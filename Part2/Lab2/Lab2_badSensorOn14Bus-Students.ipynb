{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Detecting Bad Sensors in Power System Monitoring\n",
    "\n",
    "In this lab, our goal is to detect bad sensor data measured on the IEEE 14 bus test\n",
    "system shown below. The power flow equations that couple the voltages and power flows are \n",
    "nonlinear in nature, as discussed in class. We will load the sensor data from the\n",
    "file 'sensorData14Bus.csv', and utilize SVM to perform the bad data detection.\n",
    "We aim to understand how various parameters such as the nature of the corrupt data,\n",
    "the number of corrupt data, etc., affect our abilities to classify the data.\n",
    "\n",
    "<img src=\"IEEE14bus.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we need to call the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from IPython.display import Image, display\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data \n",
    "\n",
    "Load the sensor data from the IEEE 14 bus test system, that has 14 buses\n",
    " and 20 branches. The data has been generated by adding a small noise\n",
    " to feasible voltages and power flows.\n",
    "     \n",
    "     Columns 1-14 contain bus voltage magnitudes.\n",
    "     \n",
    "     Columns 15-28 contain bus voltage phase angles.\n",
    "     \n",
    "     Columns 29-48 contain real power flow on all branches.\n",
    "     \n",
    "     Columns 49-68 contain reactive power flow on all branches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 26\n"
     ]
    }
   ],
   "source": [
    "nBuses = 14\n",
    "nBranches = 20\n",
    "\n",
    "# Select the bus numbers you monitor. For convenience, we have selected it for you.\n",
    "# The '-1' makes them columns as per Python's convention of starting to number\n",
    "# from 0.\n",
    "busesToSample = np.array([1, 2, 5, 10, 13]) - 1\n",
    "columnsForBuses = np.concatenate((busesToSample, busesToSample + 14))\n",
    "\n",
    "# Select the branches that you monitor.\n",
    "branchesToSample = np.array([1, 3, 5, 10, 11, 15, 17, 20]) - 1\n",
    "columnsForBranches = np.concatenate((branchesToSample + 28,\n",
    "                                     branchesToSample + 48))\n",
    "\n",
    "# Load the sensor data from the file 'sensorData14Bus.csv' in 'X' from the columns\n",
    "# specified in 'columnsForBuses' and 'columnsForBranches'. The csv file is comma\n",
    "# separated. Read a maximum of 5000 lines. Make sure your data is a numpy array\n",
    "# with each column typecast as 'np.float32'.\n",
    "X = np.genfromtxt('sensorData14Bus.csv', dtype=np.float32, delimiter=',',\n",
    "                  usecols=np.concatenate((columnsForBuses, columnsForBranches)),\n",
    "                  max_rows=5000)\n",
    "\n",
    "nDataPoints = np.shape(X)[0]\n",
    "nFeatures = np.shape(X)[1]\n",
    "\n",
    "print(\"Loaded sensor data on IEEE 14 bus system.\")\n",
    "print(\"Number of data points = %d, number of features = %d\"\n",
    "      % (nDataPoints, nFeatures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curroption Models \n",
    "\n",
    "Intentionally corrupt the first 'nCorrupt' rows of the data by adding\n",
    " a quantity to one or two sensor measurements that is not representative of\n",
    " our error model. We aim to study what nature of corruption is easier\n",
    " or difficult to detect.\n",
    " Specifically, we shall study 3 different models:\n",
    " \n",
    "     1. 'corruptionModel' = 1 : Add a random number with a bias to one of the measurements.\n",
    "     \n",
    "     2. 'corruptionModel' = 2 : Add a random number without bias to one of the measurements.\n",
    "     \n",
    "     3. 'corruptionModel' = 3 : Add a random number with a bias to both the measurements.\n",
    "     \n",
    "In all these cases, we will multiply the sensor data by either a uniform or a normal random number multiplied by 'multiplicationFactor'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a corruption model.\n",
    "nCorrupt = int(nDataPoints/3)\n",
    "corruptionModel = 1\n",
    "multiplicationFactor = 0.5\n",
    "\n",
    "# Choose which data to tamper with, that can be a voltage magnitude,\n",
    "# voltage phase angle, real power flow on a branch, reactive power flow\n",
    "# on a branch. We create functions to extract the relevant column to\n",
    "# corrupt the corresponding data in the 'ii'-th bus or branch.\n",
    "voltageMagnitudeColumn = lambda ii: ii\n",
    "\n",
    "voltageAngleColumn = lambda ii: ii + np.shape(busesToSample)[0]\n",
    "\n",
    "realPowerColumn = lambda ii: ii + 2*np.shape(busesToSample)[0]\n",
    "reactivePowerColumn = lambda ii: ii + 2*np.shape(busesToSample)[0] + np.shape(branchesToSample)[0]\n",
    "\n",
    "# Encode two different kinds of columns to corrupt.\n",
    "# Option 1: Corrupt real power columns only.\n",
    "# Option 2: Corrupt real power and voltage magnitude.\n",
    "columnsToCorruptOption = 2\n",
    "\n",
    "if columnsToCorruptOption == 1:\n",
    "    columnsToCorrupt = [realPowerColumn(1),\n",
    "                        realPowerColumn(2)]\n",
    "else:\n",
    "    columnsToCorrupt = [voltageMagnitudeColumn(0),\n",
    "                        realPowerColumn(1)]\n",
    "\n",
    "# Corrupt the data appropriately, given the options.\n",
    "for index in range(nCorrupt):\n",
    "\n",
    "    if corruptionModel == 1:\n",
    "        X[index, columnsToCorrupt[0]] \\\n",
    "            *= (1 + multiplicationFactor * np.random.rand())\n",
    "    elif corruptionModel == 2:\n",
    "        X[index, columnsToCorrupt[0]] \\\n",
    "            *= (1 + multiplicationFactor * np.random.randn())\n",
    "    else:\n",
    "        X[index, columnsToCorrupt[0]] \\\n",
    "            *= (1 + multiplicationFactor * np.random.rand())\n",
    "        X[index, columnsToCorrupt[1]] \\\n",
    "            *= (1 + multiplicationFactor * np.random.rand())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It is always a good practice to scale your data to run SVM. Notice that we are\n",
    " cheating a little when we scale the entire data set 'X', because our training and\n",
    " test sets are derived from 'X'. Ideally, one would have to scale the training\n",
    " and test sets separately. Create the appropriate labels and shuffle the lists 'X' and 'Y' together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = preprocessing.StandardScaler().fit_transform(X)\n",
    "\n",
    "# Create the labels as a column of 1's for the first 'nCorrupt' rows, and\n",
    "# 0's for the rest.\n",
    "Y = np.concatenate((np.ones(nCorrupt), np.zeros(nDataPoints-nCorrupt)))\n",
    "\n",
    "\n",
    "# Shuffle the features and the labels together.\n",
    "XY = list(zip(X, Y))\n",
    "np.random.shuffle(XY)\n",
    "X, Y = zip(*XY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from the first lab that 'test_size' determines what fraction of the data becomes your test set.\n",
    "\n",
    "## Task 1 (10 points)\n",
    "\n",
    "Split the dataset into two parts: training and testing.\n",
    "Store the training set in the variables 'trainX' and 'trainY'.\n",
    " Store the testing set in the variables 'testX' and 'testY.\n",
    " Reserve 20% of the data for testing.\n",
    "The function 'train_test_split' may prove useful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (10 points)\n",
    "\n",
    " Define the support vector machine classifier and train on the variables 'trainX' and 'trainY'. Use the SVC library from sklearn.svm. Only specify three hyper-parameters: 'kernel', 'degree', and 'max_iter'. Limit the maximum number of iterations to 100000 at the most. Set the kernel to be a linear classifier first. You may have to change it to report the results with other kernels. The parameter 'degree' specifies the degree for polynomial kernels. This parameter is not used for other kernels. The functions 'svm.SVC' and 'fit' will prove useful.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(degree=1, kernel='linear', max_iter=100000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enter your code here\n",
    "classifier = svm.SVC(kernel='linear', degree=1, max_iter=100000)\n",
    "classifier.fit(trainX, trainY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 (10 points)\n",
    "\n",
    "Predict the labels on the 'testX' dataset and store them in 'predictY'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here\n",
    "predictY = classifier.predict(testX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 (10 points)\n",
    "\n",
    "Print the 'classification_report' to see how well 'predictY' matches with 'testY'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98       671\n",
      "         1.0       1.00      0.91      0.96       329\n",
      "\n",
      "    accuracy                           0.97      1000\n",
      "   macro avg       0.98      0.96      0.97      1000\n",
      "weighted avg       0.97      0.97      0.97      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Enter your code here\n",
    "print(classification_report(testY, predictY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print svm's internal accuracy score as a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier.score:  0.972\n"
     ]
    }
   ],
   "source": [
    "# Enter your code here\n",
    "print('classifier.score: ',classifier.score(testX, testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "\n",
    "We would like to compare 'classification_report' with this score for various runs. Let us consider the following cases: \n",
    "\n",
    "### Case 1:\n",
    "\n",
    "Only have sensor measurements from the first 5 branches. Choose option 1 in the 'columnsToCorruptOption'. Examine how well linear kernels perform when 'corruptionModel' = 1, 'corruptionModel' = 2, and 'corruptionModel'= 3. In case linear kernels do not perform well, you may try 'rbf' or polynomial kernels with degree 2.\n",
    "\n",
    "### Case 2:\n",
    "\n",
    "Choose 'corruptionModel = 1' with 'linear' kernel. Does it pay to monitor voltage magnitudes than power flows? In other words, do you consistently get better results when you choose 'columnsToCorruptOption' as 2? Make these judgements using the average score of at least 5 runs.\n",
    "\n",
    "\n",
    "#### Your task is to investigate the above two cases. You may add a few 'Markdown' and 'Code' cells below with your comments, code, and results. You can also report your results as a pandas DataFrame. You are free to report your results in your own way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(nBuses=14, nBranches=20):\n",
    "    # Select the bus numbers you monitor. For convenience, we have selected it for you.\n",
    "    # The '-1' makes them columns as per Python's convention of starting to number\n",
    "    # from 0.\n",
    "    busesToSample = np.array([1, 2, 5, 10, 13]) - 1\n",
    "    columnsForBuses = np.concatenate((busesToSample, busesToSample + 14))\n",
    "\n",
    "    # Select the branches that you monitor.\n",
    "    branchesToSample = np.array([1, 3, 5, 10, 11, 15, 17, 20]) - 1\n",
    "    columnsForBranches = np.concatenate((branchesToSample + 28,\n",
    "                                        branchesToSample + 48))\n",
    "\n",
    "    # Load the sensor data from the file 'sensorData14Bus.csv' in 'X' from the columns\n",
    "    # specified in 'columnsForBuses' and 'columnsForBranches'. The csv file is comma\n",
    "    # separated. Read a maximum of 5000 lines. Make sure your data is a numpy array\n",
    "    # with each column typecast as 'np.float32'.\n",
    "    X = np.genfromtxt('sensorData14Bus.csv', dtype=np.float32, delimiter=',',\n",
    "                      usecols=np.concatenate((columnsForBuses, columnsForBranches)),\n",
    "                      max_rows=5000)\n",
    "\n",
    "    nDataPoints = np.shape(X)[0]\n",
    "    nFeatures = np.shape(X)[1]\n",
    "\n",
    "    print(\"Loaded sensor data on IEEE 14 bus system.\")\n",
    "    print(\"Number of data points = %d, number of features = %d\"\n",
    "          % (nDataPoints, nFeatures))\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def add_corruption(X, corruptionModel=1, columnsToCorruptOption=2, multiplicationFactor=0.5):\n",
    "    # Choose a corruption model.\n",
    "    nDataPoints = np.shape(X)[0]\n",
    "    nFeatures = np.shape(X)[1]\n",
    "    nCorrupt = int(nDataPoints/3)\n",
    "\n",
    "    # Choose which data to tamper with, that can be a voltage magnitude,\n",
    "    # voltage phase angle, real power flow on a branch, reactive power flow\n",
    "    # on a branch. We create functions to extract the relevant column to\n",
    "    # corrupt the corresponding data in the 'ii'-th bus or branch.\n",
    "    def voltageMagnitudeColumn(ii): return ii\n",
    "\n",
    "    def voltageAngleColumn(ii): return ii + np.shape(busesToSample)[0]\n",
    "\n",
    "    def realPowerColumn(ii): return ii + 2*np.shape(busesToSample)[0]\n",
    "    def reactivePowerColumn(ii): return ii + 2*np.shape(busesToSample)[0] + np.shape(branchesToSample)[0]\n",
    "\n",
    "    # Encode two different kinds of columns to corrupt.\n",
    "    # Option 1: Corrupt real power columns only.\n",
    "    # Option 2: Corrupt real power and voltage magnitude.\n",
    "\n",
    "    if columnsToCorruptOption == 1:\n",
    "        columnsToCorrupt = [realPowerColumn(1),\n",
    "                            realPowerColumn(2)]\n",
    "    else:\n",
    "        columnsToCorrupt = [voltageMagnitudeColumn(0),\n",
    "                            realPowerColumn(1)]\n",
    "\n",
    "    # Corrupt the data appropriately, given the options.\n",
    "    for index in range(nCorrupt):\n",
    "\n",
    "        if corruptionModel == 1:\n",
    "            X[index, columnsToCorrupt[0]] \\\n",
    "                *= (1 + multiplicationFactor * np.random.rand())\n",
    "        elif corruptionModel == 2:\n",
    "            X[index, columnsToCorrupt[0]] \\\n",
    "                *= (1 + multiplicationFactor * np.random.randn())\n",
    "        else:\n",
    "            X[index, columnsToCorrupt[0]] \\\n",
    "                *= (1 + multiplicationFactor * np.random.rand())\n",
    "            X[index, columnsToCorrupt[1]] \\\n",
    "                *= (1 + multiplicationFactor * np.random.rand())\n",
    "    return X\n",
    "\n",
    "\n",
    "def preprocess_data(X):\n",
    "    nDataPoints = np.shape(X)[0]\n",
    "    nFeatures = np.shape(X)[1]\n",
    "    nCorrupt = int(nDataPoints/3)\n",
    "\n",
    "    X = preprocessing.StandardScaler().fit_transform(X)\n",
    "\n",
    "    # Create the labels as a column of 1's for the first 'nCorrupt' rows, and\n",
    "    # 0's for the rest.\n",
    "    Y = np.concatenate((np.ones(nCorrupt), np.zeros(nDataPoints-nCorrupt)))\n",
    "\n",
    "    # Shuffle the features and the labels together.\n",
    "    XY = list(zip(X, Y))\n",
    "    np.random.shuffle(XY)\n",
    "    X, Y = zip(*XY)\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def train_and_test_svm(X, Y, kernel='linear', degree=1, printResult=True):\n",
    "    trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "    classifier = svm.SVC(kernel=kernel, degree=degree, max_iter=100000)\n",
    "\n",
    "    classifier.fit(trainX, trainY)\n",
    "\n",
    "    predictY = classifier.predict(testX)\n",
    "\n",
    "    report = classification_report(testY, predictY)\n",
    "    score = classifier.score(testX, testY)\n",
    "\n",
    "    if(printResult):\n",
    "        print(report)\n",
    "        print('classifier.score: ', score)\n",
    "\n",
    "    return report, score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case1\n",
    "\n",
    "| kernel | corruptionModel | accuracy |\n",
    "| ------ | --------------- | -------- |\n",
    "| linear | 1.0             | 0.979    |\n",
    "| linear | 2.0             | 0.658    |\n",
    "| linear | 3.0             | 0.970    |\n",
    "| rbf    | 1.0             | 0.941    |\t\n",
    "| rbf    | 2.0             | 0.831    |\t\n",
    "| rbf    | 3.0             | 0.966    |\t\n",
    "| poly   | 1.0             | 0.820    |\n",
    "| poly   | 2.0             | 0.850    |\n",
    "| poly   | 3.0             | 0.825    |\n",
    "\n",
    "- Data are in dataFrame.\n",
    "- For corruptionModel = 1 and 3, linear has the best accracy.\n",
    "- For corruptionModel = 2, poly with degree = 2 has the best accracy.\n",
    "- Rbf has the best average accuracy for all corruptionModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------linear corruptionModel=1------------\n",
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98       683\n",
      "         1.0       1.00      0.93      0.97       317\n",
      "\n",
      "    accuracy                           0.98      1000\n",
      "   macro avg       0.99      0.97      0.98      1000\n",
      "weighted avg       0.98      0.98      0.98      1000\n",
      "\n",
      "classifier.score:  0.979\n",
      "------------------------------------------------\n",
      "------------linear corruptionModel=2------------\n",
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lspss95207/.local/share/virtualenvs/Part2-wSLtOOJs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lspss95207/.local/share/virtualenvs/Part2-wSLtOOJs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lspss95207/.local/share/virtualenvs/Part2-wSLtOOJs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      1.00      0.79       658\n",
      "         1.0       0.00      0.00      0.00       342\n",
      "\n",
      "    accuracy                           0.66      1000\n",
      "   macro avg       0.33      0.50      0.40      1000\n",
      "weighted avg       0.43      0.66      0.52      1000\n",
      "\n",
      "classifier.score:  0.658\n",
      "------------------------------------------------\n",
      "------------linear corruptionModel=3------------\n",
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98       651\n",
      "         1.0       1.00      0.92      0.96       349\n",
      "\n",
      "    accuracy                           0.97      1000\n",
      "   macro avg       0.98      0.96      0.97      1000\n",
      "weighted avg       0.97      0.97      0.97      1000\n",
      "\n",
      "classifier.score:  0.97\n",
      "------------------------------------------------\n",
      "------------rbf corruptionModel=1------------\n",
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96       662\n",
      "         1.0       1.00      0.83      0.90       338\n",
      "\n",
      "    accuracy                           0.94      1000\n",
      "   macro avg       0.96      0.91      0.93      1000\n",
      "weighted avg       0.95      0.94      0.94      1000\n",
      "\n",
      "classifier.score:  0.941\n",
      "------------------------------------------------\n",
      "------------rbf corruptionModel=2------------\n",
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      1.00      0.89       661\n",
      "         1.0       0.99      0.50      0.67       339\n",
      "\n",
      "    accuracy                           0.83      1000\n",
      "   macro avg       0.90      0.75      0.78      1000\n",
      "weighted avg       0.86      0.83      0.81      1000\n",
      "\n",
      "classifier.score:  0.831\n",
      "------------------------------------------------\n",
      "------------rbf corruptionModel=3------------\n",
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.98       688\n",
      "         1.0       1.00      0.89      0.94       312\n",
      "\n",
      "    accuracy                           0.97      1000\n",
      "   macro avg       0.98      0.95      0.96      1000\n",
      "weighted avg       0.97      0.97      0.97      1000\n",
      "\n",
      "classifier.score:  0.966\n",
      "------------------------------------------------\n",
      "------------poly corruptionModel=1------------\n",
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      1.00      0.88       676\n",
      "         1.0       0.98      0.45      0.62       324\n",
      "\n",
      "    accuracy                           0.82      1000\n",
      "   macro avg       0.89      0.72      0.75      1000\n",
      "weighted avg       0.85      0.82      0.80      1000\n",
      "\n",
      "classifier.score:  0.82\n",
      "------------------------------------------------\n",
      "------------poly corruptionModel=2------------\n",
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lspss95207/.local/share/virtualenvs/Part2-wSLtOOJs/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      1.00      0.90       669\n",
      "         1.0       1.00      0.55      0.71       331\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.91      0.77      0.80      1000\n",
      "weighted avg       0.88      0.85      0.84      1000\n",
      "\n",
      "classifier.score:  0.85\n",
      "------------------------------------------------\n",
      "------------poly corruptionModel=3------------\n",
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      1.00      0.89       693\n",
      "         1.0       1.00      0.43      0.60       307\n",
      "\n",
      "    accuracy                           0.82      1000\n",
      "   macro avg       0.90      0.71      0.74      1000\n",
      "weighted avg       0.86      0.82      0.80      1000\n",
      "\n",
      "classifier.score:  0.825\n",
      "------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>corruptionModel</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.979</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.658</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>linear</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.970</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rbf</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.831</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rbf</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.966</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>poly</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.820</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>poly</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.850</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>poly</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.825</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kernel  corruptionModel  accuracy  \\\n",
       "0  linear              1.0     0.979   \n",
       "1  linear              2.0     0.658   \n",
       "2  linear              3.0     0.970   \n",
       "3     rbf              1.0     0.941   \n",
       "4     rbf              2.0     0.831   \n",
       "5     rbf              3.0     0.966   \n",
       "6    poly              1.0     0.820   \n",
       "7    poly              2.0     0.850   \n",
       "8    poly              3.0     0.825   \n",
       "\n",
       "                                              report  \n",
       "0                precision    recall  f1-score   ...  \n",
       "1                precision    recall  f1-score   ...  \n",
       "2                precision    recall  f1-score   ...  \n",
       "3                precision    recall  f1-score   ...  \n",
       "4                precision    recall  f1-score   ...  \n",
       "5                precision    recall  f1-score   ...  \n",
       "6                precision    recall  f1-score   ...  \n",
       "7                precision    recall  f1-score   ...  \n",
       "8                precision    recall  f1-score   ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataFrame = pd.DataFrame(\n",
    "    {\n",
    "        \"kernel\": [],\n",
    "        \"corruptionModel\": [],\n",
    "        \"accuracy\": [],\n",
    "        \"report\": [],\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "corruptionModels = [1, 2, 3]\n",
    "kernels = [('linear', 0), ('rbf', 0), ('poly', 2)]\n",
    "\n",
    "\n",
    "for kernel in kernels:\n",
    "    for corruptionModel in corruptionModels:\n",
    "        print(f\"------------{kernel[0]} corruptionModel={corruptionModel}------------\")\n",
    "\n",
    "        X = load_data(nBranches=5)\n",
    "        X = add_corruption(X, corruptionModel=corruptionModel)\n",
    "        X, Y = preprocess_data(X)\n",
    "        report, score = train_and_test_svm(X, Y, kernel=kernel[0], degree=kernel[1])\n",
    "\n",
    "        dataFrame = dataFrame.append(\n",
    "            {\n",
    "                \"kernel\": kernel[0],\n",
    "                \"corruptionModel\": corruptionModel,\n",
    "                \"accuracy\": score,\n",
    "                \"report\": report\n",
    "            }, ignore_index=True\n",
    "        )\n",
    "\n",
    "        print(\"------------------------------------------------\")\n",
    "\n",
    "\n",
    "display(dataFrame)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eec62ee2c18d3e40f084005c66b6bf13347fdd2e2ab274e29e7eb7ee8dc8168c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('Part2-wSLtOOJs': pipenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
